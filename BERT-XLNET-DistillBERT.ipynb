{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import transformers\n",
    "from transformers import BertTokenizer\n",
    "from transformers import DistilBertTokenizer, RobertaTokenizer\n",
    "from tensorflow.keras.optimizers import Adam, SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.columns = ['class','text']\n",
    "test.columns = ['class','text']\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(train)):\n",
    "    if train['class'][i] == 2:\n",
    "        train['class'][i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(test)):\n",
    "    if test['class'][i] == 2:\n",
    "        test['class'][i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_encode(data,maximum_length) :\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "  \n",
    "\n",
    "    for i in range(len(data.text)):\n",
    "        encoded = tokenizer.encode_plus(\n",
    "        \n",
    "        data.text[i],\n",
    "        add_special_tokens=True,\n",
    "        max_length=maximum_length,\n",
    "        pad_to_max_length=True,\n",
    "        \n",
    "        return_attention_mask=True,\n",
    "        \n",
    "      )\n",
    "      \n",
    "        input_ids.append(encoded['input_ids'])\n",
    "        attention_masks.append(encoded['attention_mask'])\n",
    "    return np.array(input_ids),np.array(attention_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_ids,train_attention_masks = bert_encode(train[:50000],60)\n",
    "test_input_ids,test_attention_masks = bert_encode(test[:20000],60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(bert_model):\n",
    "    input_ids = tf.keras.Input(shape=(60,),dtype='int32')\n",
    "    attention_masks = tf.keras.Input(shape=(60,),dtype='int32')\n",
    "    \n",
    "    output = bert_model([input_ids,attention_masks])\n",
    "    output = output[1]\n",
    "    \n",
    "    output = tf.keras.layers.Dense(32,activation='relu')(output)\n",
    "    output = tf.keras.layers.Dropout(0.2)(output)\n",
    "\n",
    "    output = tf.keras.layers.Dense(1,activation='sigmoid')(output)\n",
    "    model = tf.keras.models.Model(inputs = [input_ids,attention_masks],outputs = output)\n",
    "    model.compile(Adam(lr=6e-5), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFBertModel\n",
    "bert_model = TFBertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(bert_model)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "plot_model(model, to_file='model.png', expand_nested=True, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy = train[:50000]\n",
    "targets = dummy['class'].values\n",
    "\n",
    "dummy2 = test[:20000]\n",
    "targets_y = dummy2['class'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit([train_input_ids,train_attention_masks],targets,validation_data=([test_input_ids,test_attention_masks],targets_y), epochs=6,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Accuracy Curves')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Loss Curves')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFXLNetModel, XLNetTokenizer\n",
    "xlnet_model = 'xlnet-base-cased'\n",
    "xlnet_tokenizer = XLNetTokenizer.from_pretrained(xlnet_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_xlnet(xlnet_model):\n",
    "    word_inputs = tf.keras.Input(shape=(60,), name='word_inputs', dtype='int32')\n",
    "\n",
    "    \n",
    "    xlnet = TFXLNetModel.from_pretrained(xlnet_model)\n",
    "    xlnet_encodings = xlnet(word_inputs)[0]\n",
    "\n",
    "    # Collect last step from last hidden state (CLS)\n",
    "    doc_encoding = tf.squeeze(xlnet_encodings[:, -1:, :], axis=1)\n",
    "    \n",
    "    doc_encoding = tf.keras.layers.Dropout(.1)(doc_encoding)\n",
    "     \n",
    "    outputs = tf.keras.layers.Dense(1, activation='sigmoid', name='outputs')(doc_encoding)\n",
    "\n",
    "    model = tf.keras.Model(inputs=[word_inputs], outputs=[outputs])\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(lr=6e-5), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlnet = create_model_xlnet(xlnet_model)\n",
    "xlnet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(xlnet, to_file='model_xl.png', expand_nested=True, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_xl = xlnet.fit(train_input_ids,targets,validation_data=(test_input_ids,targets_y), epochs=6,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history_xl.history['accuracy'])\n",
    "plt.plot(history_xl.history['val_accuracy'])\n",
    "plt.title('Accuracy Curves')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history_xl.history['loss'])\n",
    "plt.plot(history_xl.history['val_loss'])\n",
    "plt.title('Loss Curves')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizer, TFDistilBertForSequenceClassification\n",
    "MODEL_NAME = 'distilbert-base-uncased'\n",
    "MAX_LEN = 20\n",
    "\n",
    "# initializing tokenizer\n",
    "tkzr = DistilBertTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training the dataset\n",
    "N_EPOCHS = 5\n",
    "\n",
    "model = TFDistilBertForSequenceClassification.from_pretrained(MODEL_NAME)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=6e-5)\n",
    "loss='binary_crossentropy'\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n",
    "\n",
    "history_db = model.fit(train_input_ids,targets,validation_data=(test_input_ids,targets_y), epochs=6,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history_db.history['accuracy'])\n",
    "plt.plot(history_db.history['val_accuracy'])\n",
    "plt.title('Accuracy Curves')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history_db.history['accuracy'])\n",
    "plt.plot(history_db.history['val_accuracy'])\n",
    "plt.title('Accuracy Curves')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu_tf",
   "language": "python",
   "name": "gpu_tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
